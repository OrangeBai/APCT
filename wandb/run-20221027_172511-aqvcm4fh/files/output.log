Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/orange/Programs/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:210: LightningDeprecationWarning: The `LightningModule.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_<train/validation/test>_epoch_end` instead.
  rank_zero_deprecation(
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
Missing logger folder: /home/orange/Main/Experiment/ICLR/cifar10/vgg13_test/lightning_logs
/home/orange/Programs/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/orange/Main/Experiment/ICLR/cifar10/vgg13_test exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Files already downloaded and verified
Files already downloaded and verified
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name          | Type             | Params
---------------------------------------------------
0 | model         | VGG              | 28.3 M
1 | attack        | Vanilla          | 28.3 M
2 | loss_function | CrossEntropyLoss | 0
---------------------------------------------------
28.3 M    Trainable params
0         Non-trainable params
28.3 M    Total params
56.696    Total estimated model params size (MB)




















Epoch 0:  93%|██████████████████████████████████████████████████████████████████████████████      | 435/468 [00:42<00:03, 10.12it/s, loss=1.38, v_num=0]

Validation DataLoader 0:  58%|███████████████████████████████████████████████████▉                                      | 45/78 [00:01<00:00, 37.63it/s]
/home/orange/Programs/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:535: PossibleUserWarning: It is recommended to use `self.log('lr', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.




















Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████▊| 467/468 [00:42<00:00, 10.90it/s, loss=1.09, v_num=0]




















Epoch 2:  83%|█████████████████████████████████████████████████████████████████████▏             | 390/468 [00:41<00:08,  9.49it/s, loss=0.951, v_num=0]





















Epoch 3:  85%|███████████████████████████████████████████████████████████████████████▉             | 396/468 [00:41<00:07,  9.57it/s, loss=0.8, v_num=0]





















Epoch 4:  92%|████████████████████████████████████████████████████████████████████████████▌      | 432/468 [00:42<00:03, 10.28it/s, loss=0.752, v_num=0]





















Epoch 5:  89%|█████████████████████████████████████████████████████████████████████████▊         | 416/468 [00:42<00:05,  9.71it/s, loss=0.653, v_num=0]





















Epoch 6:  91%|███████████████████████████████████████████████████████████████████████████▌       | 426/468 [00:42<00:04, 10.08it/s, loss=0.593, v_num=0]





















Epoch 7:  90%|████████████████████████████████████████████████████████████████████████████         | 419/468 [00:42<00:04,  9.87it/s, loss=0.6, v_num=0]





















Epoch 8:  87%|████████████████████████████████████████████████████████████████████████▎          | 408/468 [00:42<00:06,  9.70it/s, loss=0.617, v_num=0]




















Epoch 9:  99%|██████████████████████████████████████████████████████████████████████████████████▎| 464/468 [00:40<00:00, 11.51it/s, loss=0.563, v_num=0]











