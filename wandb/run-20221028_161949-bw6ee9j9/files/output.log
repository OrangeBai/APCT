Using 16bit native Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/orange/Programs/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:210: LightningDeprecationWarning: The `LightningModule.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `LightningModule.on_<train/validation/test>_epoch_end` instead.
  rank_zero_deprecation(
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------
Missing logger folder: /home/orange/Main/Experiment/ICLR/cifar10/vgg13_test/lightning_logs
/home/orange/Programs/anaconda3/envs/pytorch/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/orange/Main/Experiment/ICLR/cifar10/vgg13_test exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Files already downloaded and verified
Files already downloaded and verified
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name          | Type             | Params
---------------------------------------------------
0 | model         | VGG              | 28.3 M
1 | attack        | Vanilla          | 28.3 M
2 | loss_function | CrossEntropyLoss | 0
---------------------------------------------------
28.3 M    Trainable params
0         Non-trainable params
28.3 M    Total params
56.696    Total estimated model params size (MB)
Sanity Checking DataLoader 0:   0%|                                                                                               | 0/2 [00:00<?, ?it/s]t1: 0.11213541030883789
t2: 0.14210915565490723
t1: 5.0358593463897705
t2: 5.0366387367248535
t3: 5.0676867961883545
t1: 0.10016894340515137
t2: 0.12951326370239258
t1: 1.6674244403839111
t2: 1.670961618423462
t3: 1.716209888458252
t1: 0.04717373847961426
t2: 0.06306862831115723
t1: 1.3687732219696045
t2: 1.3699612617492676
t3: 1.3844795227050781
t1: 0.054825782775878906
t2: 0.06841731071472168
t1: 1.555429220199585
t2: 1.5585150718688965
t3: 1.5722978115081787
t1: 0.012937545776367188
t2: 0.020776987075805664
t1: 1.034846305847168
t2: 1.0389025211334229
t3: 1.0503380298614502
t1: 0.018911123275756836
t2: 0.029104232788085938
t1: 1.4985690116882324
t2: 1.4996497631072998
t3: 1.50571870803833
t1: 0.0077686309814453125
t2: 0.013097763061523438
t1: 1.0749847888946533
t2: 1.077979326248169
t3: 1.0890207290649414
t1: 0.0174410343170166
t2: 0.02487468719482422
t1: 2.026385545730591
t2: 2.0293397903442383
t3: 2.0401811599731445
t1: 0.008618593215942383
t2: 0.01320648193359375
t1: 1.0772922039031982
t2: 1.0778930187225342
t3: 1.0793395042419434
t1: 0.0049343109130859375
t2: 0.007047891616821289
t1: 1.0363333225250244
t2: 1.0370612144470215
t3: 1.0389184951782227
t1: 0.007699012756347656
t2: 0.01376962661743164
t1: 1.3631844520568848
t2: 1.3656136989593506
t3: 1.3741319179534912
t1: 0.014753580093383789
t2: 0.021326780319213867
t1: 1.8488194942474365
t2: 1.8526029586791992
t3: 1.8595216274261475
t1: 0.0009000301361083984
t2: 0.0029535293579101562
t1: 11.403229713439941
t2: 11.40697169303894
t3: 11.408469915390015
